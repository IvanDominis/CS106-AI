{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary libraries"
      ],
      "metadata": {
        "id": "Vs6XRNm3vkBx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhSyhfEy4XSD"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython import display\n",
        "import time"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHf1dAVKAcZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d3292b5-b62f-4a1e-9a59-810e86c381a5"
      },
      "source": [
        "env = gym.make('FrozenLake-v1')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-6usoQHAmqh",
        "outputId": "4e20f715-ff25-40d2-f9fc-5097d0dff27f"
      },
      "source": [
        "env.P[0][3] # Transition model"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.3333333333333333, 1, 0.0, False),\n",
              " (0.3333333333333333, 0, 0.0, False),\n",
              " (0.3333333333333333, 0, 0.0, False)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh7Su0h0AqQz",
        "outputId": "83651e84-d853-44a4-ee96-3e39ff4c4343"
      },
      "source": [
        "env.observation_space.n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ68w5bpBScC",
        "outputId": "2b227b54-66a9-45cb-c907-48b5bf8c4e10"
      },
      "source": [
        "env.action_space.n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWLnvY7VBvIZ"
      },
      "source": [
        "def play(env, policy, render=False):\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "    steps = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = policy[state]\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "        total_reward += reward\n",
        "        steps += 1\n",
        "        if render:\n",
        "            env.render()\n",
        "            time.sleep(0.2)\n",
        "            if not done:\n",
        "                display.clear_output(wait=True)\n",
        "        state = next_state\n",
        "\n",
        "    return (total_reward, steps)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcuDDx6rC5YE",
        "outputId": "62533b0b-ac59-4881-868b-5a4e437d1b64"
      },
      "source": [
        "policy_0 = np.asarray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "play(env, policy_0)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 55)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "tdyjjtGZC9NX",
        "outputId": "3b6c8aa5-af84-49f9-bac4-a4569d9100e7"
      },
      "source": [
        "policy_1 = np.asarray([0, 1, 1, 3, 1, 0, 2, 0, 1, 1, 2, 2, 3, 3, 1, 0])\n",
        "play(env, policy_1, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b37896233fe9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpolicy_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-a92a8235ecbf>\u001b[0m in \u001b[0;36mplay\u001b[0;34m(env, policy, render)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m             )\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrender_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m     ) -> Optional[Union[RenderFrame, List[RenderFrame]]]:\n\u001b[1;32m    420\u001b[0m         \u001b[0;34m\"\"\"Renders the environment.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m             )\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrender_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/wrappers/order_enforcing.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;34m\"set `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             )\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m             )\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrender_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m     ) -> Optional[Union[RenderFrame, List[RenderFrame]]]:\n\u001b[1;32m    420\u001b[0m         \u001b[0;34m\"\"\"Renders the environment.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m             )\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrender_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/wrappers/env_checker.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecked_render\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecked_render\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0menv_render_passive_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py\u001b[0m in \u001b[0;36menv_render_passive_checker\u001b[0;34m(env, *args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             )\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;31m# TODO: Check that the result is correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m             )\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrender_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/toy_text/frozen_lake.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_render\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"human\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/toy_text/frozen_lake.py\u001b[0m in \u001b[0;36m_render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"human\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rgb_array\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"single_rgb_array\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_gui\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_render_gui\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/toy_text/frozen_lake.py\u001b[0m in \u001b[0;36m_render_gui\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_surface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_caption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Frozen Lake\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"human\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: No available video device"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU8Q1qMxD6Po"
      },
      "source": [
        "def play_multiple_times(env, policy, max_episodes):\n",
        "    success = 0\n",
        "    list_of_steps = []\n",
        "    for i in range(max_episodes):\n",
        "        total_reward, steps = play(env, policy)\n",
        "\n",
        "        if total_reward > 0:\n",
        "            success += 1\n",
        "            list_of_steps.append(steps)\n",
        "\n",
        "    print(f'Number of successes: {success}/{max_episodes}')\n",
        "    print(f'Average number of steps: {np.mean(list_of_steps)}')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G427z17PEmjQ",
        "outputId": "896a2686-2898-4933-a8fc-61054a22b52e"
      },
      "source": [
        "policy_0 = np.asarray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "play_multiple_times(env, policy_0, 1000)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 0/1000\n",
            "Average number of steps: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1bkhaFdDmj_",
        "outputId": "06ed97f9-2ad4-47ce-ea6a-088b65da5f37"
      },
      "source": [
        "policy_1 = np.asarray([0, 1, 1, 3, 1, 0, 2, 0, 1, 1, 2, 2, 3, 3, 1, 0])\n",
        "play_multiple_times(env, policy_1, 1000)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 44/1000\n",
            "Average number of steps: 12.477272727272727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZYhsb_VEtuR",
        "outputId": "ac314f5f-6f2b-4e02-ce24-dbc777cf3560"
      },
      "source": [
        "policy_2 = np.array([1, 1, 1, 3, 0, 1, 2, 3, 1, 1, 2, 3, 2, 2, 1, 3])\n",
        "play_multiple_times(env, policy_2, 1000)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 93/1000\n",
            "Average number of steps: 16.397849462365592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvvHdMesEzTH",
        "outputId": "82a4fe7e-7fbd-47d2-f115-e3d0965ad9aa"
      },
      "source": [
        "policy_3 = np.array([0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1, 0])\n",
        "play_multiple_times(env, policy_3, 1000)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 742/1000\n",
            "Average number of steps: 36.23450134770889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Policy Evaluation Function"
      ],
      "metadata": {
        "id": "9UGHRJ9CvtAB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSomNpxJE5lP"
      },
      "source": [
        "def policy_evaluation(env, policy, max_iters=500, gamma=0.9):\n",
        "    # Initialize the values of all states to be 0\n",
        "    v_values = np.zeros(env.observation_space.n)\n",
        "\n",
        "    for i in range(max_iters):\n",
        "        prev_v_values = np.copy(v_values)\n",
        "\n",
        "        # Update the value of each state\n",
        "        for state in range(env.observation_space.n):\n",
        "            action = policy[state]\n",
        "\n",
        "            # Compute the q-value of the action\n",
        "            q_value = 0\n",
        "            for prob, next_state, reward, done in env.P[state][action]:\n",
        "                q_value += prob * (reward + gamma * prev_v_values[next_state])\n",
        "\n",
        "            v_values[state] = q_value # update v-value\n",
        "        \n",
        "        # Check convergence\n",
        "        if np.all(np.isclose(v_values, prev_v_values)):\n",
        "            print(f'Converged at {i}-th iteration.')\n",
        "            break\n",
        "    \n",
        "    return v_values"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7IhqEOgGkQX",
        "outputId": "b3045bfa-21bf-4901-9f17-f626d3b37916"
      },
      "source": [
        "policy_0 = np.asarray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "v_values_0 = policy_evaluation(env, policy_0)\n",
        "print(v_values_0)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 0-th iteration.\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMjJKI3GGrsN",
        "outputId": "e15397e0-1e9f-4ace-ffa1-d0ca3a51a894"
      },
      "source": [
        "policy_1 = np.asarray([0, 1, 1, 3, 1, 0, 2, 0, 1, 1, 2, 2, 3, 3, 1, 0])\n",
        "v_values_1 = policy_evaluation(env, policy_1)\n",
        "print(v_values_1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 48-th iteration.\n",
            "[0.01904157 0.01519815 0.03161906 0.02371389 0.02538879 0.\n",
            " 0.06648515 0.         0.05924054 0.13822794 0.18999823 0.\n",
            " 0.         0.21152109 0.56684236 0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-26M77nEfcV",
        "outputId": "00280dbd-213b-400e-83de-f1cecd998a75"
      },
      "source": [
        "np.all(v_values_1 >= v_values_0)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l49O1N8QG0S2",
        "outputId": "ca5843e7-4259-45bb-8a18-fb814ed7f5ac"
      },
      "source": [
        "policy_2 = np.array([1, 1, 1, 3, 0, 1, 2, 3, 1, 1, 2, 3, 2, 2, 1, 3])\n",
        "v_values_2 = policy_evaluation(env, policy_2)\n",
        "print(v_values_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 53-th iteration.\n",
            "[0.02889625 0.01951972 0.03616977 0.0271268  0.04790519 0.\n",
            " 0.07391985 0.         0.08288277 0.19339319 0.21022995 0.\n",
            " 0.         0.35153135 0.62684674 0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22pRvreGE3Yt",
        "outputId": "ebf2a1a8-58cf-43cb-ecf4-916a0dc15067"
      },
      "source": [
        "np.all(v_values_2 >= v_values_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTYYFq6BEXDd",
        "outputId": "5e116d6e-30c8-45b0-8469-13e1721179c6"
      },
      "source": [
        "policy_3 = np.array([0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1, 0])\n",
        "v_values_3 = policy_evaluation(env, policy_3)\n",
        "print(v_values_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 80-th iteration.\n",
            "[0.06888666 0.06141097 0.07440714 0.05580443 0.09185068 0.\n",
            " 0.11220679 0.         0.14543323 0.24749485 0.29961611 0.\n",
            " 0.         0.37993438 0.63901935 0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcEfU3NYE7xN",
        "outputId": "7009ee61-304a-4c7c-b360-5eef99980630"
      },
      "source": [
        "np.all(v_values_3 >= v_values_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Value Iteration Function"
      ],
      "metadata": {
        "id": "BEkeznkavxyG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh4akjMSHJBF"
      },
      "source": [
        "def value_iteration(env, max_iters=500, gamma=0.9):\n",
        "    # initialize\n",
        "    v_values = np.zeros(env.observation_space.n)\n",
        "\n",
        "    for i in range(max_iters):\n",
        "        prev_v_values = np.copy(v_values)\n",
        "\n",
        "        # update the v-value for each state\n",
        "        for state in range(env.observation_space.n):\n",
        "            q_values = []\n",
        "            \n",
        "            # compute the q-value for each action that we can perform at the state\n",
        "            for action in range(env.action_space.n):\n",
        "                q_value = 0\n",
        "                # loop through each possible outcome\n",
        "                for prob, next_state, reward, done in env.P[state][action]:\n",
        "                    q_value += prob * (reward + gamma * prev_v_values[next_state])\n",
        "                \n",
        "                q_values.append(q_value)\n",
        "            \n",
        "            # select the max q-values\n",
        "            best_action = np.argmax(q_values)\n",
        "            v_values[state] = q_values[best_action]\n",
        "        \n",
        "        # check convergence\n",
        "        if np.all(np.isclose(v_values, prev_v_values)):\n",
        "            print(f'Converged at {i}-th iteration.')\n",
        "            break\n",
        "    \n",
        "    return v_values"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8xAljw7VuMP",
        "outputId": "13c9c6e3-c6b7-457f-9e5e-bcc4249522dd"
      },
      "source": [
        "optimal_v_values = value_iteration(env, max_iters=500, gamma=0.9)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 79-th iteration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7g9VA3lV2WW",
        "outputId": "d496ccdf-73d5-4a11-b0cb-9bea12288a6b"
      },
      "source": [
        "optimal_v_values"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.06888615, 0.06141054, 0.07440682, 0.05580409, 0.09185022,\n",
              "       0.        , 0.11220663, 0.        , 0.14543286, 0.2474946 ,\n",
              "       0.29961593, 0.        , 0.        , 0.3799342 , 0.63901926,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Policy Extraction Function"
      ],
      "metadata": {
        "id": "IrBNNdENv6W8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb0an7gaV39e"
      },
      "source": [
        "def policy_extraction(env, v_values, gamma=0.9):\n",
        "    # initialize\n",
        "    policy = np.zeros(env.observation_space.n, dtype=np.int)\n",
        "\n",
        "    # loop through each state in the environment\n",
        "    for state in range(env.observation_space.n):\n",
        "        q_values = []\n",
        "        # loop through each action\n",
        "        for action in range(env.action_space.n):\n",
        "            q_value = 0\n",
        "            # loop each possible outcome\n",
        "            for prob, next_state, reward, done in env.P[state][action]:\n",
        "                q_value += prob * (reward + gamma * v_values[next_state])\n",
        "            \n",
        "            q_values.append(q_value)\n",
        "        \n",
        "        # select the best action\n",
        "        best_action = np.argmax(q_values)\n",
        "        policy[state] = best_action\n",
        "    \n",
        "    return policy"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TGCF4G7XErH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8147e142-d8b8-4038-b043-092e84f87577"
      },
      "source": [
        "optimal_policy = policy_extraction(env, optimal_v_values, gamma=0.9)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-9e926206ddb9>:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  policy = np.zeros(env.observation_space.n, dtype=np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-m4ZqWZXKqG",
        "outputId": "26d2955a-d40f-4097-9422-e4ff3817ad0b"
      },
      "source": [
        "optimal_policy\n",
        "play_multiple_times(env, optimal_policy, 1000)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 746/1000\n",
            "Average number of steps: 36.91018766756032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZY-vM9YXMRX",
        "outputId": "78e3285e-42da-40aa-9ecc-ec21cce9f948"
      },
      "source": [
        "play_multiple_times(env, policy_1, 1000)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 49/1000\n",
            "Average number of steps: 11.510204081632653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Policy Iteration Function"
      ],
      "metadata": {
        "id": "J7fvSPnYv8QV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def policy_iteration(env,max_iters=500, gamma=0.9):\n",
        "  # initialize\n",
        "  policy = np.zeros(env.observation_space.n)\n",
        "  for i in range(max_iters):\n",
        "    # Compute new value of policy evaluation \n",
        "    new_value = policy_evaluation(env,policy)\n",
        "    # Extracted new policy from the computed value\n",
        "    new_policy = policy_extraction(env,new_value)\n",
        "    # check convergence\n",
        "    if np.all(np.isclose(policy,new_policy)):\n",
        "      print(f'Policy-Iteration converged at {i}-th iteration.')\n",
        "      break\n",
        "    policy = new_policy\n",
        "  return policy"
      ],
      "metadata": {
        "id": "HVC2O-0-JfxO"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_policy_1 = policy_iteration(env)\n",
        "play_multiple_times(env,optimal_policy_1,1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4Z62po8u2Gl",
        "outputId": "d5b7d8f5-62c9-4676-ed4c-6ddb545870f1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 0-th iteration.\n",
            "Converged at 23-th iteration.\n",
            "Converged at 59-th iteration.\n",
            "Converged at 62-th iteration.\n",
            "Converged at 79-th iteration.\n",
            "Converged at 80-th iteration.\n",
            "Policy-Iteration converged at 5-th iteration.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-9e926206ddb9>:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  policy = np.zeros(env.observation_space.n, dtype=np.int)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 754/1000\n",
            "Average number of steps: 37.3448275862069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare between Value Iteraion and Policy Iteration"
      ],
      "metadata": {
        "id": "HYeacCGbweiQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Value Iteration"
      ],
      "metadata": {
        "id": "FfCvrEgqwsj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('FROZEN-LAKE-V1 USING VALUE ITERATION')\n",
        "s = time.time()\n",
        "optimal_v_values = value_iteration(env, max_iters=500, gamma=0.9)\n",
        "optimal_policy = policy_extraction(env, optimal_v_values, gamma=0.9)\n",
        "play_multiple_times(env, optimal_policy, 1000)\n",
        "e = time.time()\n",
        "print('Executable time:',e-s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNFpwLYlwr8B",
        "outputId": "7558377a-8273-4b03-fd6f-462474efd2fd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FROZEN-LAKE-V1 USING VALUE ITERATION\n",
            "Converged at 79-th iteration.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-9e926206ddb9>:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  policy = np.zeros(env.observation_space.n, dtype=np.int)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 741/1000\n",
            "Average number of steps: 38.232118758434545\n",
            "Executable time: 0.8577351570129395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('FROZEN-LAKE-8X8-V0 USING VALUE ITERATION')\n",
        "env1 = gym.make('FrozenLake8x8-v1')\n",
        "s = time.time()\n",
        "optimal_v_values = value_iteration(env1, max_iters=500, gamma=0.9)\n",
        "optimal_policy = policy_extraction(env1, optimal_v_values, gamma=0.9)\n",
        "play_multiple_times(env1, optimal_policy, 1000)\n",
        "e = time.time()\n",
        "print('Executable time:',e-s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb3gbH7d02Dz",
        "outputId": "0fce04c0-5587-4d64-89b4-80a048eb90d9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FROZEN-LAKE-8X8-V0 USING VALUE ITERATION\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 117-th iteration.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-9e926206ddb9>:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  policy = np.zeros(env.observation_space.n, dtype=np.int)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 727/1000\n",
            "Average number of steps: 70.47317744154057\n",
            "Executable time: 1.70347261428833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('TAXI-V3 USING VALUE ITERATION')\n",
        "env2= gym.make('Taxi-v3')\n",
        "s = time.time()\n",
        "optimal_v_values = value_iteration(env2, max_iters=500, gamma=0.9)\n",
        "optimal_policy = policy_extraction(env2, optimal_v_values, gamma=0.9)\n",
        "play_multiple_times(env2, optimal_policy, 1000)\n",
        "e = time.time()\n",
        "print('Executable time:',e-s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMOLMj051JWI",
        "outputId": "d5ca8325-666d-40ac-ed31-5f67948f2d40"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TAXI-V3 USING VALUE ITERATION\n",
            "Converged at 116-th iteration.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-9e926206ddb9>:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  policy = np.zeros(env.observation_space.n, dtype=np.int)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 1000/1000\n",
            "Average number of steps: 13.123\n",
            "Executable time: 4.39072847366333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Policy Iteration"
      ],
      "metadata": {
        "id": "z2V-Xk21xAQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = time.time()\n",
        "optimal_policy_1 = policy_iteration(env)\n",
        "play_multiple_times(env,optimal_policy_1,1000)\n",
        "e = time.time()\n",
        "print('Executable time:',e-s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFRdTRslwltP",
        "outputId": "598e9272-9d41-4f4b-eb24-0a7f1921f187"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 0-th iteration.\n",
            "Converged at 23-th iteration.\n",
            "Converged at 59-th iteration.\n",
            "Converged at 62-th iteration.\n",
            "Converged at 79-th iteration.\n",
            "Converged at 80-th iteration.\n",
            "Policy-Iteration converged at 5-th iteration.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-9e926206ddb9>:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  policy = np.zeros(env.observation_space.n, dtype=np.int)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 728/1000\n",
            "Average number of steps: 37.58379120879121\n",
            "Executable time: 0.8271799087524414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = time.time()\n",
        "optimal_policy_1 = policy_iteration(env1)\n",
        "play_multiple_times(env1,optimal_policy_1,1000)\n",
        "e = time.time()\n",
        "print('Executable time:',e-s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tH-Z-vh20Bo",
        "outputId": "cd80a602-67ad-4aea-f722-4e33373b610b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 27-th iteration.\n",
            "Converged at 91-th iteration.\n",
            "Converged at 92-th iteration.\n",
            "Converged at 86-th iteration.\n",
            "Converged at 90-th iteration.\n",
            "Converged at 92-th iteration.\n",
            "Converged at 95-th iteration.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-9e926206ddb9>:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  policy = np.zeros(env.observation_space.n, dtype=np.int)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 100-th iteration.\n",
            "Converged at 112-th iteration.\n",
            "Converged at 117-th iteration.\n",
            "Policy-Iteration converged at 9-th iteration.\n",
            "Number of successes: 753/1000\n",
            "Average number of steps: 72.18857901726427\n",
            "Executable time: 2.159482955932617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = time.time()\n",
        "optimal_policy_1 = policy_iteration(env2)\n",
        "play_multiple_times(env2,optimal_policy_1,1000)\n",
        "e = time.time()\n",
        "print('Executable time:',e-s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EirnSpQQ24mF",
        "outputId": "1b7ee33c-3ea6-4a7a-82f1-68c88440174d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 88-th iteration.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-9e926206ddb9>:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  policy = np.zeros(env.observation_space.n, dtype=np.int)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 97-th iteration.\n",
            "Converged at 100-th iteration.\n",
            "Converged at 101-th iteration.\n",
            "Converged at 102-th iteration.\n",
            "Converged at 103-th iteration.\n",
            "Converged at 106-th iteration.\n",
            "Converged at 109-th iteration.\n",
            "Converged at 110-th iteration.\n",
            "Converged at 111-th iteration.\n",
            "Converged at 112-th iteration.\n",
            "Converged at 115-th iteration.\n",
            "Converged at 116-th iteration.\n",
            "Converged at 116-th iteration.\n",
            "Converged at 116-th iteration.\n",
            "Converged at 116-th iteration.\n",
            "Converged at 116-th iteration.\n",
            "Policy-Iteration converged at 16-th iteration.\n",
            "Number of successes: 1000/1000\n",
            "Average number of steps: 13.164\n",
            "Executable time: 7.745406150817871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observation of two algorithms when running on three gym game environments"
      ],
      "metadata": {
        "id": "iUdZ5a2y5DeS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kt qu chy:\n",
        "\n",
        "- FrozenLake-V1: \n",
        "\n",
        "  VI: Converged at 79th iteration, NoS: 741/1000, Step: 38.232118758434545, Time :  0.8577351570129395\n",
        "\n",
        "  PI: Converged at 5th iteration, NoS: 728/1000, Step: 37.58379120879121, Time: 0.8271799087524414\n",
        "\n",
        "\n",
        "- FrozenLake8x8-V1:\n",
        "\n",
        "  VI: Converged at 117th iteration, NoS: 727/1000, Step: 70.47317744154057, Time :  1.70347261428833\n",
        "\n",
        "  PI: Converged at 9th iteration, NoS: 753/1000, Step: 72.18857901726427, Time: 2.159482955932617\n",
        "\n",
        "- Taxi-V3:\n",
        "\n",
        "  VI: Converged at 116th iteration, NoS: 1000/1000, Step: 13.123, Time : 4.39072847366333\n",
        "\n",
        "  PI: Converged at 16th iteration, NoS: 1000/1000, Step:13.164, Time: 7.745406150817871\n"
      ],
      "metadata": {
        "id": "71UsAj3b7f62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nhn xt:\n",
        "- Policy Iteration hi t kh sm so vi Value Iteration (Policy Iteration s i tnh nhiu gi tr hn v cho ra nhiu policy hn nn s nhanh chng hi t so vi Value Iteration ch i 1 ln n khi no hi t)\n",
        "\n",
        "-  V Policy Iteration i tm policy tt nht (tm n khi no hi t) nn s vng lp trong Policy Iteration s nhiu hn so vi Value Iteration. \n",
        "\n",
        "-  Policy Iteration v Value Iteration cho ra s ln thnh cng, bc i trung bnh v thi gian gn ging nhau c th l  FrozenLake-V1 th s ln thnh cng v bc i trung bnh khng chnh nhau qu nhiu. Cn  hai game cn li l FrozenLake8x8-V1 v Taxi-V3 khng xut hin s khc bit nhiu. \n",
        "\n",
        "-  FrozenLake8x8-V1 th s ln thnh cng ca PI ln hn VI 26 ln, cn thi gian th chm hn khong 0.4s. \n",
        "\n",
        "- Cui cng l Taxi-V3, vi thi gian chy ca Policy Iteration ln hn gn gp i so vi thi gian chy ca Value Iteration (V Policy Iteration xi kh nhiu vng lp)\n",
        "\n",
        "- Policy Iteration l mt thut ton chy n khi no hi t v chin lc bc i c cp nht v qu trnh ny lp li lin tc. Ngc li, vi Value Iteration th ch chy mi bc i, tm ra gi tr ca chin lc  v n s thc hin hnh ng c gi tr ln nht. Nn Value Iteration s nng v mt tnh ton v lu tr v phi lu li cc gi tr tng ng vi mi bc. \n",
        "\n",
        "- Tm li, vi vic s dng mi trng gym game, ta c th thy Value Iteration nhanh hn Policy Iteration v mt thi gian, cn kt qu th kh ging nhau. Trn thc t th Policy Iteration s nhanh hn Value Iteration (c th l v mt hi t) ty thuc vo mi trng m thut ton c s dng. Nn khng chc v vic kt lun thut ton no s tt hn ci cn li c. "
      ],
      "metadata": {
        "id": "L-QiC3cZ5g08"
      }
    }
  ]
}